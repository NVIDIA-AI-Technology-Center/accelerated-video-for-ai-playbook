{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ed29a0",
   "metadata": {},
   "source": [
    "# Video File Formats\n",
    "\n",
    "> A video file format is a type of file format for storing digital video data on a computer system. Video is almost always stored using lossy compression to reduce the file size. *wikipedia*\n",
    "\n",
    "Normally a video is in a **container** with visual data and audio data. The container can also have many other useful information as metadata, title, subtitles, etc.\n",
    "\n",
    "In most of the cases, in order to save memory, the visual and audio data are stored with lossy compressions.\n",
    "\n",
    "More details and comparisons:\n",
    " 1. [Video File Format](https://en.wikipedia.org/wiki/Video_file_format)\n",
    " 2. [Comparison of Container Formats](https://en.wikipedia.org/wiki/Comparison_of_video_container_formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0886ee2d",
   "metadata": {},
   "source": [
    "# Video Data Handling\n",
    "\n",
    "There are two aspects to consider for accelerated video data handling in the context of machine learning, the availability of hardware accelerated decoding and efficient video frame indicization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb8957b",
   "metadata": {},
   "source": [
    "## Hardware Accelerated Decoding\n",
    "\n",
    "We intentionally focus on decoding here. In fact, to train a VLM, we need to read TB of data, making accelerated data reading essential to complete trainings in a reasonable time.\n",
    "\n",
    "We all know the GPU is a powerful piece of hardware that can crunch huge loads of parallel computations very quickly. What many might not know is that the GPU has many specialized cores inside separated from the CUDA cores, and there are video decoding cores (and in many GPUs also encoding cores).\n",
    "\n",
    "![immagine](assets/nvcodec.jpg)\n",
    "\n",
    "A tipical setting is to use FFmpeg and decode the video data in CPU before sending it on the GPU for the model training. This can be a bottleneck and to improve it we can compile FFmpeg with NVIDIA GPU acceleration such that FFmpeg can perform hardware accelerated video decoding.\n",
    "\n",
    "More details on [NVCODEC Docs](https://docs.nvidia.com/video-technologies/video-codec-sdk/12.2/index.html#ffmpeg-with-nvidia-gpu)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a2b7c",
   "metadata": {},
   "source": [
    "##  Indexing Friendly Video Formats\n",
    "\n",
    "Formats that use keyframes and support random access tend to be more indexing-friendly. These allow for quicker seeking to specific points in the video without having to decode all preceding frames. The efficiency of indexing can also depend on how the video was encoded within the container. Videos with regular keyframe intervals are generally easier to index and seek through.\n",
    "\n",
    "Some container formats known for good indexing support include:\n",
    " - MP4 (MPEG-4 Part 14)\n",
    " - MKV (Matroska)\n",
    " - AVI (Audio Video Interleave)\n",
    " - MOV (QuickTime File Format)\n",
    "\n",
    "Side Note: It's worth noting that the efficiency of indexing can also depend on the specific implementation of the video processing library or tool being used, not just the inherent properties of the video format itself.\n",
    "\n",
    "Citations:\n",
    "[1] https://imagekit.io/blog/video-indexing/\n",
    "[2] https://indexrusher.com/blog/video-compression-for-seo-formats-and-optimization/\n",
    "[3] https://www.gumlet.com/learn/video-indexing/\n",
    "[4] https://www.linkedin.com/pulse/everything-you-need-know-video-indexing-gumlet\n",
    "[5] https://cloudinary.com/guides/web-performance/video-encoding-how-it-works-formats-best-practices\n",
    "[6] https://docs.nvidia.com/deeplearning/dali/user-guide/docs/operations/nvidia.dali.fn.readers.video.html\n",
    "[7] https://docs.nvidia.com/video-technologies/video-codec-sdk/12.0/ffmpeg-with-nvidia-gpu/index.html\n",
    "[8] https://docs.nvidia.com/deeplearning/dali/user-guide/docs/operations/nvidia.dali.fn.experimental.readers.video.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7a340a",
   "metadata": {},
   "source": [
    "## Video Preprocessing\n",
    "\n",
    "In many datasets we might find videos with different container format, different resolutions, different frame rates. In addition to that, our machine learning training will usually use a standard resolution in input (*e.g.* 256x128).\n",
    "\n",
    "Assuming you already overcame the challenge of downloading or transferring your dataset to the cluster we can move of to the video preprocessing stage.\n",
    "\n",
    "To have detailed information about the video we can use\n",
    "```bash\n",
    "ffmpeg -i input.mp4\n",
    "```\n",
    "We can preprocess our videos with\n",
    "\n",
    "```bash\n",
    "ffmpeg -y -vsync 0 -hwaccel cuda -hwaccel_output_format cuda –resize 1280x720 -i input.mp4 -c:a copy -c:v h264_nvenc -b:v 5M output.mp4\n",
    "```\n",
    "where we say to ffmpeg to \n",
    " - ```-y```: Overwrite output file without asking for confirmation.\n",
    " - ```-vsync 0```: Disable video sync to potentially speed up the process.\n",
    " - ```-hwaccel cuda```: Use CUDA hardware acceleration for decoding.\n",
    " - ```-hwaccel_output_format cuda```: Set the output format of the hardware accelerated decoder to CUDA, keeping the frames on the GPU.\n",
    " - ```–resize 1280x720```: Resize the video to 1280x720 resolution. (Note: This flag seems to be incorrect. The correct flag would be -vf scale=1280:720.)\n",
    " - ```-i input.mp4```: Specify the input file.\n",
    " - ```-c:a copy```: Copy the audio stream without re-encoding.\n",
    " - ```-c:v h264_nvenc```: Use the NVIDIA H.264 encoder for video encoding.\n",
    " - ```-b:v 5M```: Set the video bitrate to 5 Mbps.\n",
    " - ```output.mp4```: Specify the output file name.\n",
    " \n",
    "We need a script to preprocess all our dataset and not manually do one video at the time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c752cc5a",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0030753",
   "metadata": {},
   "source": [
    "nvidia dali has seek video frame function? How to use it?\n",
    "\n",
    "Yes, NVIDIA DALI has functionality to seek and extract specific frames from video files. Here are the key points on how to use it:\n",
    "\n",
    "## Video Reading and Seeking\n",
    "\n",
    "DALI provides video reading capabilities through the `readers.video` operator. This operator allows you to load and decode video files, with options to control which frames are extracted.\n",
    "\n",
    "### Key Parameters for Frame Seeking\n",
    "\n",
    "1. **sequence_length**: Specifies the number of consecutive frames to extract in each sequence[1][2].\n",
    "\n",
    "2. **stride**: Controls the step size between sequences. For example, setting `stride=2` will skip every other frame[4].\n",
    "\n",
    "3. **step**: Determines the distance between the first frame of each consecutive sequence[2].\n",
    "\n",
    "4. **initial_fill**: Sets the size of the buffer used for shuffling when `random_shuffle` is enabled[1].\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "Here's a basic example of how to use the `readers.video` operator to extract frames:\n",
    "\n",
    "```python\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "\n",
    "@pipeline_def\n",
    "def video_pipe(filenames):\n",
    "    videos, labels = fn.readers.video(\n",
    "        device=\"gpu\",\n",
    "        filenames=filenames,\n",
    "        sequence_length=16,  # Extract 16 consecutive frames\n",
    "        stride=2,  # Skip every other frame\n",
    "        step=32,   # Start of each sequence is 32 frames apart\n",
    "        random_shuffle=True,\n",
    "        initial_fill=1024\n",
    "    )\n",
    "    return videos, labels\n",
    "```\n",
    "\n",
    "## Seeking to Specific Frames\n",
    "\n",
    "While DALI doesn't have a direct \"seek to frame\" function, you can achieve similar results by combining the `sequence_length`, `stride`, and `step` parameters:\n",
    "\n",
    "1. To start from a specific frame, adjust the `step` parameter.\n",
    "2. To control the spacing between extracted frames, use the `stride` parameter.\n",
    "3. To extract a certain number of frames, set the `sequence_length` parameter.\n",
    "\n",
    "For example, to start at frame 100 and extract every 5th frame for a total of 10 frames:\n",
    "\n",
    "```python\n",
    "videos, labels = fn.readers.video(\n",
    "    device=\"gpu\",\n",
    "    filenames=filenames,\n",
    "    sequence_length=10,  # Extract 10 frames\n",
    "    stride=5,            # Take every 5th frame\n",
    "    step=100,            # Start at frame 100\n",
    ")\n",
    "```\n",
    "\n",
    "## Additional Considerations\n",
    "\n",
    "- DALI uses FFmpeg for video parsing, which allows it to handle most common video container formats[1][2].\n",
    "- For variable frame rate videos, DALI will index keyframes to enable effective seeking[1].\n",
    "- The `readers.video` operator supports both CPU and GPU backends, allowing for hardware-accelerated decoding when using the GPU backend[2].\n",
    "\n",
    "By adjusting these parameters, you can effectively control which frames are extracted from your video files, allowing for flexible frame seeking and extraction in your DALI pipeline.\n",
    "\n",
    "Citations:\n",
    "[1] https://docs.nvidia.com/deeplearning/dali/user-guide/docs/operations/nvidia.dali.fn.experimental.readers.video.html\n",
    "[2] https://docs.nvidia.com/deeplearning/dali/user-guide/docs/operations/nvidia.dali.fn.readers.video.html\n",
    "[3] https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/sequence_processing/sequence_reader_simple_example.html\n",
    "[4] https://stackoverflow.com/questions/70058109/how-to-extract-frames-from-videos-at-a-certain-fps-ex-15fps-using-nvidia-dali\n",
    "[5] https://github.com/NVIDIA/VideoProcessingFramework/issues/218\n",
    "[6] https://www.run.ai/guides/ai-open-source-projects/nvidia-dali\n",
    "[7] https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/sequence_processing/index.html\n",
    "[8] https://github.com/NVIDIA/DALI/issues/2604"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c861f",
   "metadata": {},
   "source": [
    "Useful Resources\n",
    "\n",
    "https://github.com/NVIDIA/flownet2-pytorch\n",
    "\n",
    "https://github.com/NVIDIA/DALI/blob/040b354f8d3bad417f36a973e2249e4d46174273/docs/examples/sequence_processing/video/video_processing_per_frame_arguments.ipynb\n",
    "\n",
    "https://github.com/webdataset/webdataset\n",
    "\n",
    "https://developer.nvidia.com/blog/av1-encoding-and-fruc-video-performance-boosts-and-higher-fidelity-on-the-nvidia-ada-architecture/\n",
    "\n",
    "https://docs.nvidia.com/video-technologies/pynvvideocodec/pynvc-api-prog-guide/index.html#interoperability\n",
    "\n",
    "https://developer.nvidia.com/pynvvideocodec\n",
    "\n",
    "https://gitlab-master.nvidia.com/DeepStreamSDK/deepstream_libraries/-/blob/main/segmentation/main.py?ref_type=heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeebabcc",
   "metadata": {},
   "source": [
    "# DALI discussion\n",
    "\n",
    "ffmpeg could be a bottleneck because it runs on CPU for DALI?\n",
    "\n",
    "You're correct that FFmpeg running on the CPU could potentially be a bottleneck for NVIDIA DALI's video processing pipeline. Here are the key points to understand:\n",
    "\n",
    "1. DALI's video reader uses FFmpeg for parsing video containers and extracting encoded video frames[1][2]. This initial parsing step typically occurs on the CPU.\n",
    "\n",
    "2. While DALI can leverage GPU acceleration for decoding and processing video frames, the initial FFmpeg parsing step may still rely on CPU resources[1][2].\n",
    "\n",
    "3. For certain video container formats that don't support efficient indexing (like MPEG), DALI may need to use FFmpeg to seek through the video when extracting specific sequences, which can be CPU-intensive[1][2].\n",
    "\n",
    "4. The impact of FFmpeg running on CPU can vary depending on factors like video format, container type, and seeking requirements. For some workflows, it may not be a significant bottleneck, while for others it could limit overall performance.\n",
    "\n",
    "5. To mitigate potential CPU bottlenecks:\n",
    "\n",
    "   - Use video formats and containers that support efficient indexing when possible.\n",
    "   - Adjust DALI pipeline parameters like `prefetch_queue_depth` to balance CPU and GPU workloads[1][2].\n",
    "   - Consider pre-processing videos to more GPU-friendly formats if the same videos will be used repeatedly in training.\n",
    "\n",
    "6. DALI does use hardware-accelerated decoding (NVDEC) when available, which can significantly reduce CPU load for the actual frame decoding step[2].\n",
    "\n",
    "While FFmpeg's CPU usage can be a consideration, DALI's overall design aims to optimize the video processing pipeline by leveraging GPU acceleration where possible. The extent to which FFmpeg on CPU becomes a bottleneck will depend on your specific use case and video characteristics.\n",
    "\n",
    "Citations:\n",
    "[1] https://docs.nvidia.com/deeplearning/dali/user-guide/docs/operations/nvidia.dali.fn.experimental.readers.video.html\n",
    "[2] https://docs.nvidia.com/deeplearning/dali/user-guide/docs/operations/nvidia.dali.fn.readers.video.html\n",
    "[3] https://stackoverflow.com/questions/78646875/ffmpeg-cpu-usage\n",
    "[4] https://github.com/NVIDIA/DALI/issues/1012\n",
    "[5] https://docs.nvidia.com/video-technologies/video-codec-sdk/12.0/ffmpeg-with-nvidia-gpu/index.html\n",
    "[6] https://stackoverflow.com/questions/70058109/how-to-extract-frames-from-videos-at-a-certain-fps-ex-15fps-using-nvidia-dali\n",
    "[7] https://www.reddit.com/r/ffmpeg/comments/1734nf2/why_is_my_cpu_used_a_ton_when_encoding_with/\n",
    "[8] https://www.run.ai/guides/ai-open-source-projects/nvidia-dali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aec997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\r\n",
      "------------------------- --------------------\r\n",
      "absl-py                   2.0.0\r\n",
      "aiohttp                   3.8.5\r\n",
      "aiosignal                 1.3.1\r\n",
      "annotated-types           0.5.0\r\n",
      "apex                      0.1\r\n",
      "argon2-cffi               23.1.0\r\n",
      "argon2-cffi-bindings      21.2.0\r\n",
      "asttokens                 2.4.0\r\n",
      "astunparse                1.6.3\r\n",
      "async-timeout             4.0.3\r\n",
      "attrs                     23.1.0\r\n",
      "audioread                 3.0.1\r\n",
      "backcall                  0.2.0\r\n",
      "beautifulsoup4            4.12.2\r\n",
      "bleach                    6.0.0\r\n",
      "blis                      0.7.11\r\n",
      "cachetools                5.3.1\r\n",
      "catalogue                 2.0.10\r\n",
      "certifi                   2023.7.22\r\n",
      "cffi                      1.16.0\r\n",
      "charset-normalizer        3.2.0\r\n",
      "click                     8.1.6\r\n",
      "cloudpathlib              0.15.1\r\n",
      "cloudpickle               2.2.1\r\n",
      "cmake                     3.27.6\r\n",
      "comm                      0.1.4\r\n",
      "confection                0.1.3\r\n",
      "contourpy                 1.1.1\r\n",
      "cubinlinker               0.3.0+2.gce0680b\r\n",
      "cuda-python               12.2.0rc5+5.g84845d1\r\n",
      "cudf                      23.8.0\r\n",
      "cugraph                   23.8.0\r\n",
      "cugraph-dgl               23.8.0\r\n",
      "cugraph-service-client    23.8.0\r\n",
      "cugraph-service-server    23.8.0\r\n",
      "cuml                      23.8.0\r\n",
      "cupy-cuda12x              12.1.0\r\n",
      "cycler                    0.12.1\r\n",
      "cymem                     2.0.8\r\n",
      "Cython                    3.0.3\r\n",
      "dask                      2023.7.1\r\n",
      "dask-cuda                 23.8.0\r\n",
      "dask-cudf                 23.8.0\r\n",
      "debugpy                   1.8.0\r\n",
      "decorator                 5.1.1\r\n",
      "defusedxml                0.7.1\r\n",
      "distributed               2023.7.1\r\n",
      "dm-tree                   0.1.8\r\n",
      "einops                    0.7.0\r\n",
      "exceptiongroup            1.1.3\r\n",
      "execnet                   2.0.2\r\n",
      "executing                 2.0.0\r\n",
      "expecttest                0.1.3\r\n",
      "fastjsonschema            2.18.1\r\n",
      "fastrlock                 0.8.1\r\n",
      "filelock                  3.12.4\r\n",
      "flash-attn                2.0.4\r\n",
      "fonttools                 4.43.1\r\n",
      "frozenlist                1.4.0\r\n",
      "fsspec                    2023.6.0\r\n",
      "gast                      0.5.4\r\n",
      "google-auth               2.23.2\r\n",
      "google-auth-oauthlib      0.4.6\r\n",
      "graphsurgeon              0.4.6\r\n",
      "grpcio                    1.59.0\r\n",
      "hypothesis                5.35.1\r\n",
      "idna                      3.4\r\n",
      "importlib-metadata        6.8.0\r\n",
      "iniconfig                 2.0.0\r\n",
      "intel-openmp              2021.4.0\r\n",
      "ipykernel                 6.25.2\r\n",
      "ipython                   8.16.1\r\n",
      "ipython-genutils          0.2.0\r\n",
      "jedi                      0.19.1\r\n",
      "Jinja2                    3.1.2\r\n",
      "joblib                    1.3.2\r\n",
      "json5                     0.9.14\r\n",
      "jsonschema                4.19.1\r\n",
      "jsonschema-specifications 2023.7.1\r\n",
      "jupyter_client            8.3.1\r\n",
      "jupyter_core              5.3.2\r\n",
      "jupyter-tensorboard       0.2.0\r\n",
      "jupyterlab                2.3.2\r\n",
      "jupyterlab-pygments       0.2.2\r\n",
      "jupyterlab-server         1.2.0\r\n",
      "jupytext                  1.15.2\r\n",
      "kiwisolver                1.4.5\r\n",
      "langcodes                 3.3.0\r\n",
      "librosa                   0.9.2\r\n",
      "llvmlite                  0.40.1\r\n",
      "locket                    1.0.0\r\n",
      "Markdown                  3.4.4\r\n",
      "markdown-it-py            3.0.0\r\n",
      "MarkupSafe                2.1.3\r\n",
      "matplotlib                3.8.0\r\n",
      "matplotlib-inline         0.1.6\r\n",
      "mdit-py-plugins           0.4.0\r\n",
      "mdurl                     0.1.2\r\n",
      "mistune                   3.0.2\r\n",
      "mkl                       2021.1.1\r\n",
      "mkl-devel                 2021.1.1\r\n",
      "mkl-include               2021.1.1\r\n",
      "mock                      5.1.0\r\n",
      "mpmath                    1.3.0\r\n",
      "msgpack                   1.0.5\r\n",
      "multidict                 6.0.4\r\n",
      "murmurhash                1.0.10\r\n",
      "nbclient                  0.8.0\r\n",
      "nbconvert                 7.9.2\r\n",
      "nbformat                  5.9.2\r\n",
      "nest-asyncio              1.5.8\r\n",
      "networkx                  2.6.3\r\n",
      "ninja                     1.11.1.1\r\n",
      "notebook                  6.4.10\r\n",
      "numba                     0.57.1+1.g5fba9aa8f\r\n",
      "numpy                     1.22.2\r\n",
      "nvfuser                   0.0.20+gitunknown\r\n",
      "nvidia-dali-cuda120       1.30.0\r\n",
      "nvidia-pyindex            1.0.9\r\n",
      "nvtx                      0.2.5\r\n",
      "oauthlib                  3.2.2\r\n",
      "onnx                      1.14.0\r\n",
      "opencv                    4.7.0\r\n",
      "packaging                 23.1\r\n",
      "pandas                    1.5.3\r\n",
      "pandocfilters             1.5.0\r\n",
      "parso                     0.8.3\r\n",
      "partd                     1.4.0\r\n",
      "pathy                     0.10.2\r\n",
      "pexpect                   4.8.0\r\n",
      "pickleshare               0.7.5\r\n",
      "Pillow                    9.2.0\r\n",
      "pip                       23.2.1\r\n",
      "platformdirs              3.11.0\r\n",
      "pluggy                    1.3.0\r\n",
      "ply                       3.11\r\n",
      "polygraphy                0.49.0\r\n",
      "pooch                     1.7.0\r\n",
      "preshed                   3.0.9\r\n",
      "prettytable               3.9.0\r\n",
      "prometheus-client         0.17.1\r\n",
      "prompt-toolkit            3.0.39\r\n",
      "protobuf                  4.24.4\r\n",
      "psutil                    5.9.4\r\n",
      "ptxcompiler               0.8.1+1.g2cb1b35\r\n",
      "ptyprocess                0.7.0\r\n",
      "pure-eval                 0.2.2\r\n",
      "pyarrow                   11.0.0\r\n",
      "pyasn1                    0.5.0\r\n",
      "pyasn1-modules            0.3.0\r\n",
      "pybind11                  2.11.1\r\n",
      "pybind11-global           2.11.1\r\n",
      "pycocotools               2.0+nv0.7.3\r\n",
      "pycparser                 2.21\r\n",
      "pydantic                  2.4.2\r\n",
      "pydantic_core             2.10.1\r\n",
      "Pygments                  2.16.1\r\n",
      "pylibcugraph              23.8.0\r\n",
      "pylibcugraphops           23.8.0\r\n",
      "pylibraft                 23.8.0\r\n",
      "pynvml                    11.4.1\r\n",
      "pyparsing                 3.1.1\r\n",
      "pytest                    7.4.2\r\n",
      "pytest-flakefinder        1.1.0\r\n",
      "pytest-rerunfailures      12.0\r\n",
      "pytest-shard              0.1.2\r\n",
      "pytest-xdist              3.3.1\r\n",
      "python-dateutil           2.8.2\r\n",
      "python-hostlist           1.23.0\r\n",
      "pytorch-quantization      2.1.2\r\n",
      "pytz                      2023.3\r\n",
      "PyYAML                    6.0.1\r\n",
      "pyzmq                     25.1.1\r\n",
      "raft-dask                 23.8.0\r\n",
      "referencing               0.30.2\r\n",
      "regex                     2023.10.3\r\n",
      "requests                  2.31.0\r\n",
      "requests-oauthlib         1.3.1\r\n",
      "resampy                   0.4.2\r\n",
      "rmm                       23.8.0\r\n",
      "rpds-py                   0.10.4\r\n",
      "rsa                       4.9\r\n",
      "scikit-learn              1.2.0\r\n",
      "scipy                     1.11.1\r\n",
      "Send2Trash                1.8.2\r\n",
      "setuptools                68.2.2\r\n",
      "six                       1.16.0\r\n",
      "smart-open                6.4.0\r\n",
      "sortedcontainers          2.4.0\r\n",
      "soundfile                 0.12.1\r\n",
      "soupsieve                 2.5\r\n",
      "spacy                     3.7.1\r\n",
      "spacy-legacy              3.0.12\r\n",
      "spacy-loggers             1.0.5\r\n",
      "sphinx-glpi-theme         0.3\r\n",
      "srsly                     2.4.8\r\n",
      "stack-data                0.6.3\r\n",
      "sympy                     1.12\r\n",
      "tabulate                  0.9.0\r\n",
      "tbb                       2021.10.0\r\n",
      "tblib                     2.0.0\r\n",
      "tensorboard               2.9.0\r\n",
      "tensorboard-data-server   0.6.1\r\n",
      "tensorboard-plugin-wit    1.8.1\r\n",
      "tensorrt                  8.6.1\r\n",
      "terminado                 0.17.1\r\n",
      "thinc                     8.2.1\r\n",
      "threadpoolctl             3.2.0\r\n",
      "thriftpy2                 0.4.16\r\n",
      "tinycss2                  1.2.1\r\n",
      "toml                      0.10.2\r\n",
      "tomli                     2.0.1\r\n",
      "toolz                     0.12.0\r\n",
      "torch                     2.1.0a0+32f93b1\r\n",
      "torch-tensorrt            0.0.0\r\n",
      "torchdata                 0.7.0a0\r\n",
      "torchtext                 0.16.0a0\r\n",
      "torchvision               0.16.0a0\r\n",
      "tornado                   6.3.3\r\n",
      "tqdm                      4.66.1\r\n",
      "traitlets                 5.9.0\r\n",
      "transformer-engine        0.12.0+170797\r\n",
      "treelite                  3.2.0\r\n",
      "treelite-runtime          3.2.0\r\n",
      "triton                    2.1.0+e621604\r\n",
      "typer                     0.9.0\r\n",
      "types-dataclasses         0.6.6\r\n",
      "typing_extensions         4.7.1\r\n",
      "ucx-py                    0.33.0\r\n",
      "uff                       0.6.9\r\n",
      "urllib3                   1.26.16\r\n",
      "wasabi                    1.1.2\r\n",
      "wcwidth                   0.2.8\r\n",
      "weasel                    0.3.2\r\n",
      "webencodings              0.5.1\r\n",
      "Werkzeug                  3.0.0\r\n",
      "wheel                     0.41.2\r\n",
      "xdoctest                  1.0.2\r\n",
      "xgboost                   1.7.5\r\n",
      "yarl                      1.9.2\r\n",
      "zict                      3.0.0\r\n",
      "zipp                      3.16.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1d910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
